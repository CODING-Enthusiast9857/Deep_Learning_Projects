{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1245709,"sourceType":"datasetVersion","datasetId":715041}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T09:48:46.825148Z","iopub.execute_input":"2024-04-29T09:48:46.825471Z","iopub.status.idle":"2024-04-29T09:49:02.387800Z","shell.execute_reply.started":"2024-04-29T09:48:46.825445Z","shell.execute_reply":"2024-04-29T09:49:02.386691Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m801.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.8.2 sacrebleu-2.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"]=\"true\"","metadata":{"execution":{"iopub.status.busy":"2024-04-29T09:50:23.038577Z","iopub.execute_input":"2024-04-29T09:50:23.040355Z","iopub.status.idle":"2024-04-29T09:50:23.044496Z","shell.execute_reply.started":"2024-04-29T09:50:23.040317Z","shell.execute_reply":"2024-04-29T09:50:23.043552Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T09:50:32.500872Z","iopub.execute_input":"2024-04-29T09:50:32.501306Z","iopub.status.idle":"2024-04-29T09:50:40.894451Z","shell.execute_reply.started":"2024-04-29T09:50:32.501271Z","shell.execute_reply":"2024-04-29T09:50:40.893545Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"4.39.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine-tuning a model on a translation","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-mr\"","metadata":{"execution":{"iopub.status.busy":"2024-04-29T09:51:28.313745Z","iopub.execute_input":"2024-04-29T09:51:28.314208Z","iopub.status.idle":"2024-04-29T09:51:28.318686Z","shell.execute_reply.started":"2024-04-29T09:51:28.314181Z","shell.execute_reply":"2024-04-29T09:51:28.317792Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\nraw_datasets = load_dataset(\"Helsinki-NLP/opus-100\", \"en-mr\")\nmetric = load_metric(\"sacrebleu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:05:45.913765Z","iopub.execute_input":"2024-04-29T10:05:45.914427Z","iopub.status.idle":"2024-04-29T10:05:51.848006Z","shell.execute_reply.started":"2024-04-29T10:05:45.914393Z","shell.execute_reply":"2024-04-29T10:05:51.847084Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6de4f7e69d44fb9a4f84d06ce8bc8c"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 128k/128k [00:00<00:00, 439kB/s]\nDownloading data: 100%|██████████| 1.58M/1.58M [00:00<00:00, 5.06MB/s]\nDownloading data: 100%|██████████| 127k/127k [00:00<00:00, 502kB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a25a486809cd4d21b6d40a099117118d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/27007 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb5281bb1ea54240afafebc532dc3ca4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32669aed89e84c1d9167b9c554855c6a"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_34/2364442312.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"sacrebleu\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/sacrebleu/sacrebleu.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95fcd9548d70431fa96df98ff86188fa"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:06:02.545814Z","iopub.execute_input":"2024-04-29T10:06:02.546443Z","iopub.status.idle":"2024-04-29T10:06:02.552938Z","shell.execute_reply.started":"2024-04-29T10:06:02.546412Z","shell.execute_reply":"2024-04-29T10:06:02.552019Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2000\n    })\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 27007\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:06:13.954190Z","iopub.execute_input":"2024-04-29T10:06:13.954976Z","iopub.status.idle":"2024-04-29T10:06:13.968956Z","shell.execute_reply.started":"2024-04-29T10:06:13.954945Z","shell.execute_reply":"2024-04-29T10:06:13.967977Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'translation': {'en': 'Ethiopian', 'mr': 'इथियोपिक@ item Calendar system'}}"},"metadata":{}}]},{"cell_type":"code","source":"import datasets\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\ndef show_random_elements(dataset, num_examples=5):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, datasets.ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n    display(HTML(df.to_html()))\nshow_random_elements(raw_datasets[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:07:22.641407Z","iopub.execute_input":"2024-04-29T10:07:22.642059Z","iopub.status.idle":"2024-04-29T10:07:22.654093Z","shell.execute_reply.started":"2024-04-29T10:07:22.642030Z","shell.execute_reply":"2024-04-29T10:07:22.653182Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>translation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'en': 'This shouldn't happen. Please file a bug report at bugzilla.gnome.org describing how you can cause this message to appear.', 'mr': 'असे व्हायला नाही पाहिजे. कृपया bugzilla.gnome.org येथे त्रुटी अहवाल दाखल करा व हा संदेश कसे दर्शवायचे त्याचे वर्णन करा.'}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'en': 'My wife isn't beautiful. Yours is.', 'mr': 'माझी पत्नी सुंदर नाहीये. तुमची आहे.'}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'en': 'ALeastSignificant (LSB)', 'mr': 'ALeastSignificant (LSB)'}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'en': 'Do you want to remove %1 too?', 'mr': 'तुम्हाला% 1 देखिल काढूण टाकायचे?'}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'en': '&amp; Enable smartcard support', 'mr': 'स्मार्टकार्ड समर्थन कार्यान्वीत करा (E)'}</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"metric","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:11:41.148575Z","iopub.execute_input":"2024-04-29T10:11:41.149289Z","iopub.status.idle":"2024-04-29T10:11:41.156144Z","shell.execute_reply.started":"2024-04-29T10:11:41.149258Z","shell.execute_reply":"2024-04-29T10:11:41.155228Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\nProduces BLEU scores along with its sufficient statistics\nfrom a source against one or more references.\n\nArgs:\n    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n        - `'none'`: no smoothing\n        - `'floor'`: increment zero counts\n        - `'add-k'`: increment num/denom by k for n>1\n        - `'exp'`: exponential decay\n    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n        - `'none'`: No tokenization.\n        - `'zh'`: Chinese tokenization.\n        - `'13a'`: mimics the `mteval-v13a` script from Moses.\n        - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n        - `'char'`: Language-agnostic character-level tokenization.\n        - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n    lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n    force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n    use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n\nReturns:\n    'score': BLEU score,\n    'counts': Counts,\n    'totals': Totals,\n    'precisions': Precisions,\n    'bp': Brevity penalty,\n    'sys_len': predictions length,\n    'ref_len': reference length,\n\nExamples:\n\n    Example 1:\n        >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n        >>> print(list(results.keys()))\n        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n        >>> print(round(results[\"score\"], 1))\n        100.0\n\n    Example 2:\n        >>> predictions = [\"hello there general kenobi\",\n        ...                 \"on our way to ankh morpork\"]\n        >>> references = [[\"hello there general kenobi\", \"hello there !\"],\n        ...                 [\"goodbye ankh morpork\", \"ankh morpork\"]]\n        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n        >>> results = sacrebleu.compute(predictions=predictions,\n        ...                             references=references)\n        >>> print(list(results.keys()))\n        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n        >>> print(round(results[\"score\"], 1))\n        39.8\n\"\"\", stored examples: 0)"},"metadata":{}}]},{"cell_type":"code","source":"fake_preds = [\"hello there\", \"general kenobi\"]\nfake_labels = [[\"hello there\"], [\"general kenobi\"]]\nmetric.compute(predictions=fake_preds, references=fake_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:12:23.365421Z","iopub.execute_input":"2024-04-29T10:12:23.366021Z","iopub.status.idle":"2024-04-29T10:12:23.395284Z","shell.execute_reply.started":"2024-04-29T10:12:23.365990Z","shell.execute_reply":"2024-04-29T10:12:23.394485Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'score': 0.0,\n 'counts': [4, 2, 0, 0],\n 'totals': [4, 2, 0, 0],\n 'precisions': [100.0, 100.0, 0.0, 0.0],\n 'bp': 1.0,\n 'sys_len': 4,\n 'ref_len': 4}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing the data","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:12:55.124107Z","iopub.execute_input":"2024-04-29T10:12:55.124776Z","iopub.status.idle":"2024-04-29T10:12:57.169884Z","shell.execute_reply.started":"2024-04-29T10:12:55.124747Z","shell.execute_reply":"2024-04-29T10:12:57.168904Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"013151c5367c4f1c813ea83011438258"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce11c2f229b64d8db2f29f95c8a703e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6009439ed9c47fa9046ddc59b7dc136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/1.17M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"706d254be436411eb0dc49a8a2f2dc8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"648dc850b8b84821a0f4b7399ddcb132"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sacremoses","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:13:10.852856Z","iopub.execute_input":"2024-04-29T10:13:10.853699Z","iopub.status.idle":"2024-04-29T10:13:23.597929Z","shell.execute_reply.started":"2024-04-29T10:13:10.853667Z","shell.execute_reply":"2024-04-29T10:13:23.596908Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Collecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses) (2023.12.25)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses) (1.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sacremoses) (4.66.1)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:13:32.616535Z","iopub.execute_input":"2024-04-29T10:13:32.617306Z","iopub.status.idle":"2024-04-29T10:13:32.624706Z","shell.execute_reply.started":"2024-04-29T10:13:32.617269Z","shell.execute_reply":"2024-04-29T10:13:32.623739Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[50289, 3, 67, 86, 6913, 70, 0], [235, 17, 374, 6913, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer([\"Hello, what are you doing?\", \"तुम्ही काय करत आहात?\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:15:09.232623Z","iopub.execute_input":"2024-04-29T10:15:09.233325Z","iopub.status.idle":"2024-04-29T10:15:09.240524Z","shell.execute_reply.started":"2024-04-29T10:15:09.233295Z","shell.execute_reply":"2024-04-29T10:15:09.239499Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{'input_ids': [[2844, 10105, 1475, 3, 84, 43, 23, 75, 71, 9, 0], [94, 97, 213, 695, 9, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"prefix = \"\"\nmax_input_length = 128\nmax_target_length = 128\nsource_lang = \"en\"\ntarget_lang = \"mr\"\ndef preprocess_function(examples):\n    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:16:03.703680Z","iopub.execute_input":"2024-04-29T10:16:03.704644Z","iopub.status.idle":"2024-04-29T10:16:03.710760Z","shell.execute_reply.started":"2024-04-29T10:16:03.704610Z","shell.execute_reply":"2024-04-29T10:16:03.709941Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"preprocess_function(raw_datasets['train'][:2])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:16:16.177950Z","iopub.execute_input":"2024-04-29T10:16:16.178664Z","iopub.status.idle":"2024-04-29T10:16:16.186150Z","shell.execute_reply.started":"2024-04-29T10:16:16.178631Z","shell.execute_reply":"2024-04-29T10:16:16.185156Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[11906, 0], [9453, 28499, 35953, 4575, 26666, 1475, 0]], 'attention_mask': [[1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': [[53463, 4233, 6436, 54, 34525, 1054, 0], [9453, 4560, 30842, 49609, 7448, 206, 0]]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:16:31.313547Z","iopub.execute_input":"2024-04-29T10:16:31.314311Z","iopub.status.idle":"2024-04-29T10:16:39.793693Z","shell.execute_reply.started":"2024-04-29T10:16:31.314275Z","shell.execute_reply":"2024-04-29T10:16:39.792805Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4941306f19dc42abb347e6687951933d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27007 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27fae3b7c3974060a6b306a895f228c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80abb1804a0c460680dadf6629998f59"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Fine-tuning the model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:17:06.844655Z","iopub.execute_input":"2024-04-29T10:17:06.845000Z","iopub.status.idle":"2024-04-29T10:17:33.908484Z","shell.execute_reply.started":"2024-04-29T10:17:06.844972Z","shell.execute_reply":"2024-04-29T10:17:33.907626Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2024-04-29 10:17:10.866220: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 10:17:10.866325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 10:17:11.128578: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/305M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22d5ad60417d4728aae34986f29cf293"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e26c9ede574df2b39dc8528a74f65e"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=1,\n    predict_with_generate=True    \n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:17:40.388428Z","iopub.execute_input":"2024-04-29T10:17:40.389342Z","iopub.status.idle":"2024-04-29T10:17:40.519501Z","shell.execute_reply.started":"2024-04-29T10:17:40.389308Z","shell.execute_reply":"2024-04-29T10:17:40.518583Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:17:54.161543Z","iopub.execute_input":"2024-04-29T10:17:54.162397Z","iopub.status.idle":"2024-04-29T10:17:54.166616Z","shell.execute_reply.started":"2024-04-29T10:17:54.162363Z","shell.execute_reply":"2024-04-29T10:17:54.165637Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:18:29.755640Z","iopub.execute_input":"2024-04-29T10:18:29.755994Z","iopub.status.idle":"2024-04-29T10:18:29.764793Z","shell.execute_reply.started":"2024-04-29T10:18:29.755964Z","shell.execute_reply":"2024-04-29T10:18:29.763880Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:18:45.882457Z","iopub.execute_input":"2024-04-29T10:18:45.883073Z","iopub.status.idle":"2024-04-29T10:18:46.234290Z","shell.execute_reply.started":"2024-04-29T10:18:45.883043Z","shell.execute_reply":"2024-04-29T10:18:46.233450Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:18:57.811731Z","iopub.execute_input":"2024-04-29T10:18:57.812956Z","iopub.status.idle":"2024-04-29T10:24:45.451489Z","shell.execute_reply.started":"2024-04-29T10:18:57.812908Z","shell.execute_reply":"2024-04-29T10:24:45.450593Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='844' max='844' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [844/844 05:43, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.009400</td>\n      <td>2.396553</td>\n      <td>16.891400</td>\n      <td>9.677000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61673]], 'forced_eos_token_id': 0}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=844, training_loss=2.973104467889144, metrics={'train_runtime': 347.3281, 'train_samples_per_second': 77.756, 'train_steps_per_second': 2.43, 'total_flos': 195011996811264.0, 'train_loss': 2.973104467889144, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Files that are created in directory after fine-tuning","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('opus-mt-en-mr-finetuned-en-to-mr/checkpoint-500'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:28:11.059880Z","iopub.execute_input":"2024-04-29T10:28:11.060616Z","iopub.status.idle":"2024-04-29T10:28:11.066777Z","shell.execute_reply.started":"2024-04-29T10:28:11.060580Z","shell.execute_reply":"2024-04-29T10:28:11.065768Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"opus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/config.json\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/vocab.json\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/rng_state.pth\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/generation_config.json\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/trainer_state.json\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/training_args.bin\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/tokenizer_config.json\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/special_tokens_map.json\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/target.spm\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/optimizer.pt\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/model.safetensors\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/source.spm\nopus-mt-en-mr-finetuned-en-to-mr/checkpoint-500/scheduler.pt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Predict sample text","metadata":{}},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\nsrc_text = ['Where are your daughter?']\nmodel_name = 'opus-mt-en-mr-finetuned-en-to-mr/checkpoint-500'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)\ntranslated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n[tokenizer.decode(t, skip_special_tokens=True) for t in translated]","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:32:12.367202Z","iopub.execute_input":"2024-04-29T10:32:12.367792Z","iopub.status.idle":"2024-04-29T10:32:14.543314Z","shell.execute_reply.started":"2024-04-29T10:32:12.367761Z","shell.execute_reply":"2024-04-29T10:32:14.542319Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"['तुझी मुलगी कुठे आहे?']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}